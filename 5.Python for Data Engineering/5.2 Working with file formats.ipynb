{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be858957",
   "metadata": {},
   "source": [
    "### <div id=\"py\"> Working with different file formats </div>\n",
    "\n",
    "\n",
    "\n",
    "- JSON (java script object notation)\n",
    "- CSV (Command Seperated Values)\n",
    "- Excel\n",
    "- Avro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ec6af",
   "metadata": {},
   "source": [
    "### Data comes in various forms\n",
    "\n",
    "<img src=\"images/data_gen.jpeg\">\n",
    "\n",
    "As a data person you will deal with various type of data and it's important to learn how to handle these file formats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96639378",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Working in JSON files\n",
    "\n",
    "***\n",
    "Since its inception, JSON has quickly become the de facto standard for information exchange. \n",
    "\n",
    "Chances are you’re here because you need to transport some data from here to there. Perhaps you’re gathering information through an API or storing your data in a document database. \n",
    "\n",
    "One way or another, you’re up to your neck in JSON, and you’ve got to Python your way out.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945d9c7",
   "metadata": {},
   "source": [
    "## A (Very) Brief History of JSON\n",
    "\n",
    "JSON stangs for JavaScript Object Notation was inspired by a subset of the JavaScript programming language dealing with object literal syntax. \n",
    "\n",
    "Ultimately, the community at large adopted JSON because it’s easy for both humans and machines to create and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa222af9",
   "metadata": {},
   "source": [
    "### Look, it’s JSON!\n",
    "```\n",
    "{\n",
    "    \"firstName\": \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafc60f",
   "metadata": {},
   "source": [
    "### Does this look similar to something?\n",
    "\n",
    "YES! Python **dictionary!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0b925",
   "metadata": {},
   "source": [
    "### Writing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cba507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481ec6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"president\": {\n",
    "        \"name\": \"Trump\",\n",
    "        \"species\": \"USA\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd43843",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a25a4",
   "metadata": {},
   "source": [
    " Note that `dump()` takes two positional arguments:\n",
    " 1. the data object to be serialized, and\n",
    " 2. the file-like object to which the bytes will be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9f99b",
   "metadata": {},
   "source": [
    "### Reading JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60eade2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_file.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb6e862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6c5f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'president': {'name': 'Trump', 'species': 'USA'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880e5c1",
   "metadata": {},
   "source": [
    "### You can also read JSON as DataFrame in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3448afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Courses  Discount\n",
      "Index0  Azure Data Factory      1200\n",
      "Index1            AWS Glue      1500\n",
      "Index2               Spark      1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMFLYR\\AppData\\Local\\Temp\\ipykernel_15952\\684997641.py:9: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df2 = pd.read_json(jsonStr, orient ='index')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jsonStr = '''{\"Index0\":{\"Courses\": \"Azure Data Factory\",\"Discount\": \"1200\"},\n",
    "           \"Index1\":{\"Courses\": \"AWS Glue\",\"Discount\": \"1500\"},\n",
    "           \"Index2\":{\"Courses\": \"Spark\",\"Discount\": \"1800\"}\n",
    "          }'''\n",
    "\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "df2 = pd.read_json(jsonStr, orient ='index')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097b560",
   "metadata": {},
   "source": [
    "### Convert Dict To DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06bceead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Trump', 'species': 'USA'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['president']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84371c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(data, orient ='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9522c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>Trump</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name species\n",
       "president  Trump     USA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b0503",
   "metadata": {},
   "source": [
    "## Working with CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee495711",
   "metadata": {},
   "source": [
    "A CSV file (Comma Separated Values file) is a type of plain text file that uses specific structuring to arrange tabular data. \n",
    "\n",
    "It’s a plain text file that has data separated by commas!\n",
    "\n",
    "```\n",
    "column 1 name,column 2 name, column 3 name\n",
    "first row data 1,first row data 2,first row data 3\n",
    "second row data 1,second row data 2,second row data 3\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40170091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hrdata.csv', index_col='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c610f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sick Days remaining</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Graham Chapman</th>\n",
       "      <td>03/15/14</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Cleese</th>\n",
       "      <td>06/01/15</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eric Idle</th>\n",
       "      <td>05/12/14</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terry Jones</th>\n",
       "      <td>11/01/13</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terry Gilliam</th>\n",
       "      <td>08/12/14</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Hire Date   Salary  Sick Days remaining\n",
       "Name                                                  \n",
       "Graham Chapman  03/15/14  50000.0                   10\n",
       "John Cleese     06/01/15  65000.0                    8\n",
       "Eric Idle       05/12/14  45000.0                   10\n",
       "Terry Jones     11/01/13  70000.0                    3\n",
       "Terry Gilliam   08/12/14  48000.0                    7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35cb4247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMFLYR\\AppData\\Local\\Temp\\ipykernel_15952\\640411541.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv('data/hrdata.csv', index_col='Name', parse_dates=['Hire Date'])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/hrdata.csv', index_col='Name', parse_dates=['Hire Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4997f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sick Days remaining</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Graham Chapman</th>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Cleese</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eric Idle</th>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terry Jones</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terry Gilliam</th>\n",
       "      <td>2014-08-12</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Palin</th>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Hire Date   Salary  Sick Days remaining\n",
       "Name                                                   \n",
       "Graham Chapman 2014-03-15  50000.0                   10\n",
       "John Cleese    2015-06-01  65000.0                    8\n",
       "Eric Idle      2014-05-12  45000.0                   10\n",
       "Terry Jones    2013-11-01  70000.0                    3\n",
       "Terry Gilliam  2014-08-12  48000.0                    7\n",
       "Michael Palin  2013-05-23  66000.0                    8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ceed2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/hrdata_modified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e220c9",
   "metadata": {},
   "source": [
    "## Working with Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f022f",
   "metadata": {},
   "source": [
    "Excel spreadsheets are one of those things you might have to deal with at some point. Either it’s because your boss loves them or because marketing needs them, and you might have to learn how to work with spreadsheets.\n",
    "\n",
    "Many companies still prefer using Excel files for their data storage and analysis, as a data expert you should know how to handle these files programatically!\n",
    "\n",
    "To work with Excel files we have package in python `openpyxl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8954655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007e215",
   "metadata": {},
   "source": [
    "### Basics of Excel\n",
    "\n",
    "<img src=\"images/excel.png\" width=550>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ea8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "workbook = Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet[\"A1\"] = \"hello\"\n",
    "sheet[\"B1\"] = \"world!\"\n",
    "\n",
    "workbook.save(filename=\"hello_world.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f417c6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheet 1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading excel file\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "workbook = load_workbook(filename=\"data/sample-xlsx-file.xlsx\")\n",
    "workbook.sheetnames\n",
    "['Sheet 1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6576d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = workbook.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e897bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Worksheet \"Employee\">"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c837c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Employee'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bc2d417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Cell 'Employee'.A1>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet[\"A1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c029da1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Doe'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet[\"A3\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f785b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Cell 'Employee'.F10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet.cell(row=10, column=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cd98ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1965, 1, 13, 0, 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet.cell(row=3, column=3).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb1e0b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<Cell 'Employee'.A1>, <Cell 'Employee'.B1>, <Cell 'Employee'.C1>),\n",
       " (<Cell 'Employee'.A2>, <Cell 'Employee'.B2>, <Cell 'Employee'.C2>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet[\"A1:C2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192ba25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Name', 'Email', 'Date Of Birth', 'Salary', 'Department', None)\n",
      "('Rajeev Singh', 'rajeev@example.com', datetime.datetime(1992, 7, 21, 0, 0), 1500000.0, 'Software Engineering', None)\n",
      "('John Doe', 'john@example.com', datetime.datetime(1965, 1, 13, 0, 0), 1300000.0, 'Sales', None)\n",
      "('Jack Sparrow', 'jack@example.com', datetime.datetime(1986, 12, 19, 0, 0), 1000000.0, 'HR', None)\n",
      "('Steven Cook', 'steven@example.com', datetime.datetime(1994, 5, 4, 0, 0), 1200000.0, 'Marketing', None)\n",
      "(None, None, None, None, None, None)\n",
      "(None, None, None, None, None, None)\n",
      "(None, None, None, None, None, None)\n",
      "(None, None, None, None, None, None)\n",
      "(None, None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "for row in sheet.iter_rows(values_only=True):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce2761",
   "metadata": {},
   "source": [
    "### You can read Excel file as DataFrame using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96673c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df = pd.read_excel('data/sample-xlsx-file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4129976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Date Of Birth</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rajeev Singh</td>\n",
       "      <td>rajeev@example.com</td>\n",
       "      <td>1992-07-21</td>\n",
       "      <td>1500000</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>john@example.com</td>\n",
       "      <td>1965-01-13</td>\n",
       "      <td>1300000</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Sparrow</td>\n",
       "      <td>jack@example.com</td>\n",
       "      <td>1986-12-19</td>\n",
       "      <td>1000000</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steven Cook</td>\n",
       "      <td>steven@example.com</td>\n",
       "      <td>1994-05-04</td>\n",
       "      <td>1200000</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name               Email Date Of Birth   Salary  \\\n",
       "0  Rajeev Singh  rajeev@example.com    1992-07-21  1500000   \n",
       "1      John Doe    john@example.com    1965-01-13  1300000   \n",
       "2  Jack Sparrow    jack@example.com    1986-12-19  1000000   \n",
       "3   Steven Cook  steven@example.com    1994-05-04  1200000   \n",
       "\n",
       "             Department  \n",
       "0  Software Engineering  \n",
       "1                 Sales  \n",
       "2                    HR  \n",
       "3             Marketing  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1042994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df.to_excel('data/sample-xlsx-file-modifeid.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8c3c2",
   "metadata": {},
   "source": [
    "## Working with AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58db039",
   "metadata": {},
   "source": [
    "Apache Avro is a data serialization format. We can store data as `.avro` files on disk. \n",
    "\n",
    "Avro files are typically used with Spark but Spark is completely independent of Avro.\n",
    "\n",
    "Avro is a row-based format that is suitable for evolving data schemas. One benefit of using Avro is that schema and metadata travels with the data.\n",
    "\n",
    "If you have an .avro file, you have the schema of the data as well. \n",
    "\n",
    "The Apache Avro Specification provides easy-to-read yet detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78034bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: avro-python3\n",
      "  Building wheel for avro-python3 (pyproject.toml): started\n",
      "  Building wheel for avro-python3 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44039 sha256=dd4242a666f2cd313d944de8926c3ce160e7ecefff594d7657a476e2833b5ed6\n",
      "  Stored in directory: c:\\users\\imflyr\\appdata\\local\\pip\\cache\\wheels\\51\\1a\\f4\\bd962fd1830f8b34c3ba124e1fabbfcb64ccd588dd3bcf1ba9\n",
      "Successfully built avro-python3\n",
      "Installing collected packages: avro-python3\n",
      "Successfully installed avro-python3-1.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fefc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3 with `avro-python3` package available\n",
    "import copy\n",
    "import json\n",
    "import avro\n",
    "from avro.datafile import DataFileWriter, DataFileReader\n",
    "from avro.io import DatumWriter, DatumReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0b82b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note that we combined namespace and name to get \"full name\"\n",
    "schema = {\n",
    "    'name': 'avro.example.User',\n",
    "    'type': 'record',\n",
    "    'fields': [\n",
    "        {'name': 'name', 'type': 'string'},\n",
    "        {'name': 'age', 'type': 'int'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse the schema so we can use it to write the data\n",
    "schema_parsed = avro.schema.Parse(json.dumps(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd70674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<avro.schema.RecordSchema at 0x1f6f3917750>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11cbe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write data to an avro file\n",
    "with open('users.avro', 'wb') as f:\n",
    "    writer = DataFileWriter(f, DatumWriter(), schema_parsed)\n",
    "    writer.append({'name': 'Pierre-Simon Laplace', 'age': 77})\n",
    "    writer.append({'name': 'John von Neumann', 'age': 53})\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "814999d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema that we specified:\n",
      " {'name': 'avro.example.User', 'type': 'record', 'fields': [{'name': 'name', 'type': 'string'}, {'name': 'age', 'type': 'int'}]}\n",
      "Schema that we parsed:\n",
      " {\"type\": \"record\", \"name\": \"User\", \"namespace\": \"avro.example\", \"fields\": [{\"type\": \"string\", \"name\": \"name\"}, {\"type\": \"int\", \"name\": \"age\"}]}\n",
      "Schema from users.avro file:\n",
      " {'type': 'record', 'name': 'User', 'namespace': 'avro.example', 'fields': [{'type': 'string', 'name': 'name'}, {'type': 'int', 'name': 'age'}]}\n",
      "Users:\n",
      " [{'name': 'Pierre-Simon Laplace', 'age': 77}, {'name': 'John von Neumann', 'age': 53}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read data from an avro file\n",
    "with open('users.avro', 'rb') as f:\n",
    "    reader = DataFileReader(f, DatumReader())\n",
    "    metadata = copy.deepcopy(reader.meta)\n",
    "    schema_from_file = json.loads(metadata['avro.schema'])\n",
    "    users = [user for user in reader]\n",
    "    reader.close()\n",
    "\n",
    "print(f'Schema that we specified:\\n {schema}')\n",
    "print(f'Schema that we parsed:\\n {schema_parsed}')\n",
    "print(f'Schema from users.avro file:\\n {schema_from_file}')\n",
    "print(f'Users:\\n {users}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7a488",
   "metadata": {},
   "source": [
    "### Reading Avro Using Pandas\n",
    "\n",
    "Avro format simply requires a schema and a list of records. We don’t need a dataframe to handle Avro files. \n",
    "\n",
    "However, we can write a `pandas` dataframe into an Avro file or read an Avro file into a `pandas` dataframe. \n",
    "\n",
    "To begin with, we can always represent a dataframe as a list of records and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e92ddfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandavro\n",
      "  Downloading pandavro-1.8.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting fastavro<2.0.0,>=1.5.1 (from pandavro)\n",
      "  Downloading fastavro-1.10.0-cp313-cp313-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1->pandavro) (1.17.0)\n",
      "Downloading pandavro-1.8.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading fastavro-1.10.0-cp313-cp313-win_amd64.whl (483 kB)\n",
      "Installing collected packages: fastavro, pandavro\n",
      "Successfully installed fastavro-1.10.0 pandavro-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1398a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: fastavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1->pandavro) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandavro fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990cc8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288065fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pandavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: fastavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: avro-python3 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pandavro fastavro avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd872040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: fastavro in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandavro) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1->pandavro) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1->pandavro) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandavro fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3702f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: avro-python3 in c:\\users\\imflyr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8767509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import fastavro as pdx\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61a7ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name  age\n",
      "0  Pierre-Simon Laplace   77\n",
      "1      John von Neumann   53\n"
     ]
    }
   ],
   "source": [
    "# Data to be saved\n",
    "users = [{'name': 'Pierre-Simon Laplace', 'age': 77},\n",
    "         {'name': 'John von Neumann', 'age': 53}]\n",
    "users_df = pd.DataFrame.from_records(users)\n",
    "print(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to AVRO\n",
    "pdx.to_avro('data/users_test.avro', users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0237ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data back\n",
    "users_df_redux = pdx.from_avro('data/users_test.avro')\n",
    "print(type(users_df_redux))\n",
    "# <class 'pandas.core.frame.DataFrame'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db7256cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'record', 'name': 'User', 'namespace': 'avro.example', 'fields': [{'type': 'string', 'name': 'name'}, {'type': 'int', 'name': 'age'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check the schema for \"users.avro\"\n",
    "with open('users.avro', 'rb') as f:\n",
    "    reader = DataFileReader(f, DatumReader())\n",
    "    metadata = copy.deepcopy(reader.meta)\n",
    "    schema_from_file = json.loads(metadata['avro.schema'])\n",
    "    reader.close()\n",
    "print(schema_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91be078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
